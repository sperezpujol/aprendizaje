**---
title: "Técnicas de Aprendizaje Estadístico aplicadas a empresas editoriales españolas"
subtitle: "Máster Universitario en Modelización y Análisis de Datos Económicos <p> (MUMADE)"
author: 'Autores: Bermann, M.A. & Pérez, R.S.'
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
    prettydoc::html_pretty:
    theme: cayman
    highlight: vignette
lang: es
---

```{r setup, include = FALSE}
# Ajustes de los chunk
knitr::opts_chunk$set(echo = FALSE, 
                      eval = TRUE, 
                      message = FALSE,
                      warning = FALSE,
                      comment = '')
```

```{r}
# Limpieza inicial del entorno
rm(list = ls())

# Instalación de paquetes que no estén instalados
packages <- c("tidyr", "dplyr", "ggplot2", "knitr", 
              "readxl", "tibble", "kableExtra", "gt",
              "PerformanceAnalytics", "ez",
              "GGally", "stats", "ggcorrplot", "tree")
installed_packages <- packages %in% 
  rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

# Activación de paquetes
library(readxl)
library(PerformanceAnalytics)
library(tidyr)
library(dplyr)
library(ggplot2)
library(knitr)
library(tibble)
library(gt)
library(kableExtra)
library(ez)
library(GGally)
library(corrplot)
library(stats)
library(ggcorrplot)
library(tree)

```

# Resumen 

Las empresass editoriales están en una transición donde el papel se está viendo sobrepasado por todo lo que pueda sonar a "digital". En este sentido, en España, las empresas editoriales siempre han ido teniendo cierta importancia gracias a que son una vía de posicionamiento y puesta en valor de la creación artística y literaria de miles de autores, así como por ser canal de producción de productos relacionados con numerosos ámbitos (educativos, revistas, etc.). En este sentido, es de interés, aplicar técnicas de aprendizaje estadístico para poder dar uso a diferentes métodos de predicción y clasificación, utilizando para ello R.

# Importación de datos

Se han utilizado datos de 370 empresas editoriales españolas, extraídas de la base de datos empresariales Sabi (licencia: UCLM), y obteniéndose un _dataset_ bidimensional sobre las editoriales españolas. Su dimensión es de 370 x 15, con una columna identificativa con el nombre de empresa y un conjunto de variables económicas, siendo éstas:

  + reneco: la rentabilidad económica de la empresa. Es el resultado de dividir el resultado del ejercicio entre los activos empresariales.
  + renfin: la rentabilidad financiera de la empresa. Es el resultado de dividir el resultado del ejercicio entre los fondos propios.
  + liquidez: la liquidez de la empresa. Es el resultado de dividir los activos líquidos de la empresa entre sus deudas.
  + endeuda: el nivel de endeudamiento de la empresa. Es el resultado de dividir las deudas entre el total de activos.
  + fpios: fondos propios. Cantidad absoluta, en miles de euros, de fondos propios de la empresa.
 + res: resultado del ejercicio. Resultado del ejercicio absoluto, en miles de euros. 
 + ing: ingresos de explotación. Ingresos del ejercicio absolutos, en miles de euros.
 + margen: margen financiero. Es el resultado de dividir el resultado del ejercicio entre los ingressos de explotación.
 + solvencia: ratio de solvencia. Es el resultado de dividir el activo a corto plazo entre el pasivo a corto plazo, indicando la capacidad de la empresa de pagar sus deudas a corto plazo. 
 + apalanca: apalancamiento. Es el resultado de dividir la deuda entre los fondos propios.
 + tamaño: Tamaño de la empresa. Para generar esta variable cualitativa, hemos clasificado las empresas según el número de trabajadores.
 +beneficio: beneficio de la empresa. Hemos generado esta variable binaria según si la empresa tiene beneficios o pérdidas durante el ejercicio. 1 indica la existencia de beneficios, y 0 de pérdidas.

```{r}
# Importando los datos de un archivo .rds
editoriales <- 
  readRDS('dataset_aprendizaje.rds')
editoriales <- 
  data.frame(editoriales,
             row.names = 1)
editoriales$tamaño <-
  factor(editoriales$tamaño,
         levels = c("microempresa", 
                    "pequeña",
                    "mediana", 
                    "grande"), 
         labels = c("microempresa",
                    "pequeña", 
                    "mediana", 
                    "grande"))
```

A continuación, se procederá a dividir los datos en un conjunto de entrenamiento (train) y otro de validación (test). Se fija la semilla para que el resultado sea, oportunamente reproducible.

```{r}
# Partiendo la muestra en test y train
library(ISLR2)
set.seed(1)
train <- sample(300, 70)
```

# Regresión

Elige una variable **numérica** de interés del conjunto de datos, que tenga sentido predecir a partir de las demás. Si estás usando los datos de RRHH, la empresa podría estar interesada en predecir el nivel de satisfacción en función de las demás. Haz algunos gráficos y resúmenes numéricos para explorar las relaciones (correlaciones de variables numéricas, gráficos de cajas por grupos, medias por grupos, ...)

Se elige, como variable numérica dependiente, la rentabilidad financiera, con el objetivo de predecirla en función del tamaño empresarial, los ingresos de explotación y el activo de la empresa.

$renfin = f(tamaño, ing, emplea, activo)$

```{r, fig.width = 10, fig.height = 7}
# ANÁLISIS DE CORRELACIONES
model.matrix(~0+., 
             data = editoriales) %>%
  cor(use = "pairwise.complete.obs") %>%
  ggcorrplot(show.diag = F, 
             type = "lower", 
             lab=TRUE, 
             lab_size=2)
```
En primer lugar, si se realiza un análisis de correlación entre las variables, encontramos que las mayores correlaciones positivas se dan entre activo y fondos propios y activo e ingresos de explotación. También parece considerable la correlación positiva entre la variable que recoge las empresas de tamaño grande y su relación con el número de empleados y los ingresos de explotación, lo que parece algo evidente. Por su parte, las mayores correlaciones negativas.

```{r, fig.width = 10, fig.height = 7}
#DISPERSION
ggplot(data = editoriales, aes(x = row.names(editoriales), 
                               y = emplea)) +
  geom_point(size = 2, 
             alpha = 0.8, 
             colour = 'orange') +
  xlab('Empresa') +
  ylab('Empleados') + ggtitle('') +
  theme_light()+
  theme(axis.text.x = element_text(angle = 90, 
                                   size = 6,
                                   hjust = 1, 
                                   vjust = 1))

ggplot(data = editoriales, aes(x = row.names(editoriales), 
                               y = renfin)) +
  geom_point(size = 2, 
             alpha = 0.8, 
             colour = 'orange') +
  xlab('Empresa') +
  ylab('Rentabilidad financiera') + ggtitle('') +
  theme_light()+
  theme(axis.text.x = element_text(angle = 90, 
                                   size = 6,
                                   hjust = 1, 
                                   vjust = 1))

ggplot(data = editoriales, aes(y = renfin)) +
  geom_boxplot(alpha = 0.5, 
               col = "steelblue",
               fill = "orange", 
               outlier.color = "blue",
               outlier.shape = 16,
               notch = TRUE) +
  labs(title ="Rentabilidad financiera") +
  xlab("Rentabilidad financiera")+
  ylab("Empresas") +
  geom_hline(yintercept = 0)+
  theme_light()

ggplot(editoriales, 
       aes(tamaño, renfin)) +
  geom_boxplot()
```
Si se realiza un gráfico de dispersión respecto a los empleados, se observa que hay una serie de empresas de las analizadas que tienen un gran número de empleados. No obstante, al no ser una medida relativa, procedamos a plantear un gráfico de dispersión de la rentabilidad económica. Esto nos muestra que, la mayor parte de las editoriales, sitúan su rentabilidad económica en torno a 0, aunque, no obstante, se siguen observando bastantes casos que despuntan. Ya que la media es positiva, es decir, los resultados de la muestra de rentabilidad económica está sesgada en términos positivos, es una señal de que las empresas editoriales tienen una buena capacidad de generar beneficios a través de su estructura económica. No obstante, esto podría venir dado por la influencia de grandes empresas que empujan a la muestra a tener un sesgo positivo, pues gráficamente observamos también numerosos casos con rentabilidades económicas negativas.

Si observamos un gráfico de cajas, viendo la relación entre tamaño y rentabilidad financiera, observamos que las microempresas, son las que, al tener un nivel de activos inferior, presentan mayor variación en términos de rentabilidad financiera.

```{r, fig.width = 10, fig.height = 7}
Rentabilidad_Financiera <- c(editoriales$renfin)
# GRÁFICAS DE CAJAS POR GRUPOS
library(plotly)
fig <- plot_ly(y = ~Rentabilidad_Financiera,
               type = "box",
               quartilemethod = "linear",
               name="Linear Quartile Mode")
fig
```

Si analizamos la dispersión de la variable de rentabilidad económica a través de un gráfico de caja, encontramos que la mayor parte de los datos están concentrados en torno a 0 (veamos como el primer y tercer cuartil están prácticamente pegados).

Si analizamos los resultados de apalancamiento teniendo en cuenta el beneficio y tamaño de la empresa, las empresas medianas y las microempresas, tal y como hemos visto en el gráfico de cajas, se ven afectadas de forma severa por los outliers, a diferencia de las empresas pequeñas y grandes. Las empresas medianas, si nos fijamos, tienen outliers por abajo, y las microempresas por arriba y por abajo. Esto explica que las empresas medianas con beneficio positivo, no tengan tampoco un dato alto o como cabría esperar de rentabilidad financiera.

```{r}
# MEDIAS POR GRUPOS
editoriales %>%
  group_by(beneficio, tamaño) %>%
  summarise_at(vars(renfin), 
               list(name = mean))
```

# MODELOS

Ajusta **algunos** de los siguientes modelos que hemos aprendido en la asignatura con los datos de entrenamiento, y evalúa los errores en los dos conjuntos. Usa validación cruzada en aquellos en los que se haya usado en los _labs_:

- KNN
- Regresión lineal múltiple
- Regresión lineal múltiple con selección de variables
- Regresión de Ridge
- Lasso
- GAM
- PCR
- PLS
- Árbol de regresión
- Árboles usando bagging y boosting
- Random Forests
- SVMs

No es obligatorio que los hagáis todos. El mínimo es dos, para poder comparar. El código de los _labs_ os debe servir modificándolo para vuestros datos.

Aunque luego lo pongas en las conclusiones, explica aquí cuál es el mejor modelo para predecir la variable que has elegido.

## Multiple Linear Regression

Se procede a construir un modelo de regresión múltiple, estimado a través de mínimos cuadrados. Primero estimamos con todas las variables.

```{r}
lm1.fit <- lm(reneco ~ ., 
              data = editoriales,
              subset = train)
summary(lm1.fit)
```
```{r}
library(car)
vif(lm1.fit)
```

Segundo, acotamos las variables explicativas

```{r chunk14}
lm2.fit <- lm(reneco ~ beneficio + res + fpios + solvencia,
             data = editoriales,
             subset = train)
summary(lm2.fit)
```

Observamos buenos datos de significación, es decir, de relación de variables, aunque la capacidad predictiva del modelo es bastante baja.

A continuación, observamos valores altos del vif para algunas variables (endeuda, activo, fpios, ing, solvencia), lo que evidencia problemas de colinealidad en algunas variables.

```{r}
library(car)
vif(lm2.fit)
```

Ahora procederemos a la validación del modelo de regresión múltiple. En este punto, calculamos el error medio del modelo generado, utilizando información de la muestra de entrenamiento.

```{r}
attach(editoriales)
mean((reneco - predict(lm2.fit, 
                       editoriales))[-train]^2)
```
# Regression tree

```{r}
library(tree)
```

Vamos a ajustar un árbol de regresión sobre la base de datos de editoriales. Con la muestra train, ajustamos el árbol a los datos de entrenamiento
First, we create a training set, and fit the tree to the training data.

```{r chunk14}
set.seed(1)
train2 <- sample(1:nrow(editoriales), nrow(editoriales / 2))
tree.editoriales <- tree(reneco ~ .,
                    editoriales,
                    subset = train2)
summary(tree.editoriales)
```

El summary nos indica que tenemos que usar 5 variables para construir el árbol. En el contexto del árbol de regresión, la desviación es la suma de los cuadrados de los errores del árbol. Veamos gráficamente el árbol.

```{r chunk15}
plot(tree.editoriales)
text(tree.editoriales,
     pretty = 0)
```

Vemos que la variable que nos ayuda a dividir los datos en grupos más iguales es el margen. 
El punto de división del margen es 12,41. Si es mayor, el rendimiento será más alto, y si es menor, viceversa. En la parte superior del margen, la siguiente variable que permite sacar conclusiones es la rentabilidad financiera, y en menor medida fondos propios y endeudamiento. Las empresas con rentabilidad financiera más alta, tendrán una mayor rentabilidad económica. Las empresas menos endeudadas, tendrán una mauyor rentabilidad económica y fondos propios.

Vamos a ver si con menos divisiones sacaríamos mejor resultado.

```{r chunk16}
cv.editoriales <- cv.tree(tree.editoriales)
plot(cv.editoriales$size, cv.editoriales$dev, type = "b")
```

Nos nos hace falta reducir las divisiones para mejorar el árbol.

Vamos a hacer las predicciones de la muestra de validación.

```{r chunk18, eval = FALSE}
library(stats)
yhat <- predict(tree.editoriales,
                newdata = editoriales[-train2, ])
editoriales.test <- editoriales[-train2, "reneco"]
plot(yhat, editoriales.test)
abline(0, 1)
mean((yhat - editoriales.test)^2)
```

In other words, the  test set MSE associated with the regression tree is $35.29$.
The square root of the MSE is therefore around $5.941$, indicating that this model leads to test predictions that are (on average) within approximately $5{,}941$ of the true median home value for the census tract.

# Clasificación

Elige una variable **categórica** de interés del conjunto de datos, que tenga sentido predecir a partir de las demás. Si estás usando los datos de RRHH, la empresa podría estar interesada en predecir el abandono en función de las demás. Haz algunos gráficos y resúmenes numéricos para explorar las relaciones (algunos del apartado de regresión servirán para este.

Variable categórica: $tamaño$

Ajusta **algunos** de los siguientes modelos que hemos aprendido en la asignatura con los datos de entrenamiento, y evalúa los errores en los dos conjuntos. Usa validación cruzada en aquellos en los que se haya usado en los _labs_:

- KNN
- Regresión Logística
- Discriminante lineal y cuadrático
- GAM para respuesta categórica
- Árbol de regresión
- Árboles usando bagging y boosting
- Random Forests
- SVMs

Recuerda que aunque hay muchos modelos, el procedimiento es similar en todos:

1. Ajustar modelo en datos _train_
2. Predecir respuesta en datos _test_
3. Evaluar el error en datos _test_ y _train_
4. Repetir para distintos modelos
5. Comparar los modelos

Empieza por dos modelos que te resultan más fáciles, y después ve probando más. No es obligatorio ajustarlos todos.

```{r chunk1}
library(tree)
library(ISLR2)
attach(editoriales)
```

#ÁRBOL DE CLASIFICACIÓN

Vamos a realizar un árbol de clasificación y una validación cruzada. El árbol de clasificación sobre la muestra de entrenamiento, arroja una predicción cuyo acierto es del 80,50%. Por ejemplo, predice 141 microempresas de forma exacta, y por otro lado, por ejemplo, predice una microempresa como empresa grande. Respecto a la predicción sobre el total de los datos considerados, el acierto aumenta a un 91,62%, un dato incluso superior que sobre la muestra de entrenamiento, fruto a que la muestra de entrenamiento seleccionada sea, seguramente, más difícil de predecir que si se hace, como hemos visto, sobre la muestra tota (puede ser por errores más altos).

```{r chunk8}
set.seed(1)
train3 <- sample(1:nrow(editoriales),
                200)
editoriales.test2 <- editoriales[-train3, ]
tamaño.test <- tamaño[-train3]
tree.editoriales2 <- tree(tamaño ~ . - emplea, 
                         editoriales,
    subset = train3)
tree.pred <- predict(tree.editoriales2, 
                     editoriales.test2,
    type = "class")
table(tree.pred, 
      tamaño.test)
tree.predtotal <- predict(tree.editoriales2, 
                     editoriales,
    type = "class")
table(tree.predtotal, 
      tamaño)
(141+14+2+4)/200
(308+10+7+14)/370
```


# LOGISTIC REGRESSION # no nos vale de momento

```{r chunk9}
train3<-c(rep(TRUE,280), rep(FALSE,90))
?rep
set.seed(1)
attach(editoriales)
train4 <- (apalanca > 5)
editoriales3 <- editoriales[!train4, ]
dim(editoriales3)
tamaño2 <- tamaño[!train4]
```

```{r modelo lineal glm}
glm.fits <- glm(
    beneficio ~ . - emplea,
    data = editoriales, 
    family = binomial, 
    subset = train4
  )
glm.probs <- predict(glm.fits,
                     editoriales3,
    type = "response")
```

```{r chunk11}
glm.pred <- rep("Beneficio", 197)
glm.pred[glm.probs > .5] <- "Pérdida"
table(glm.pred, tamaño2)
mean(glm.pred == tamaño2)
mean(glm.pred != tamaño2)
```

#KNN

```{r chunk26}
library(class)
train.X <- cbind(reneco, 
                 renfin, 
                 liquidez, 
                 solvencia, 
                 ing, 
                 endeuda, 
                 emplea, 
                 activo,
                 fpios,
                 res,
                 ing,
                 margen,
                 apalanca,
                 beneficio)[train3, ]
test.X <- cbind(reneco, 
                 renfin, 
                 liquidez, 
                 solvencia, 
                 ing, 
                 endeuda, 
                 emplea, 
                 activo,
                 fpios,
                 res,
                 ing,
                 margen,
                 apalanca,
                 beneficio)[!train3, ]
train.tamaño <- tamaño[train3]
```

```{r chunk27}
tamaño5 <- tamaño[!train3]
tamaño6 <- tamaño[train3]
set.seed(1)
knn.predtrain <- knn(train.X,
                train.X,
                train.tamaño,
                k = 4)
table(knn.predtrain, 
      tamaño6)
(227+10+9+10)/280
knn.predtest <- knn(train.X,
                test.X,
                train.tamaño,
                k = 4)
table(knn.predtest, 
      tamaño5)
(75+2+5) / 90

```**

---
title: "Trabajo de Aprendizaje Estadístico | Proyecto <p> Técnicas de Aprendizaje Estadístico aplicadas a empresas editoriales españolas"
subtitle: "Máster Universitario en Modelización y Análisis de Datos Económicos <p> (MUMADE)"
author: 'Autores: Bermann, M.A. & Pérez, R.S. [Grupo D]'
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
    prettydoc::html_pretty:
    theme: cayman
    highlight: vignette
lang: es
---

```{r setup, include = FALSE}
# Ajustes de los chunk
knitr::opts_chunk$set(echo = FALSE, 
                      eval = TRUE, 
                      message = FALSE,
                      warning = FALSE,
                      comment = '')
```

```{r inicio, include = FALSE}
# Limpieza inicial del entorno
rm(list = ls())

# Instalacion de paquetes que no estén instalados
packages <- c("tidyr",
              "dplyr",
              "ggplot2",
              "knitr", 
              "readxl",
              "tibble",
              "kableExtra",
              "gt",
              "PerformanceAnalytics",
              "ez",
              "GGally",
              "stats",
              "ggcorrplot",
              "tree",
              "car",
              "ISLR2",
              "stats",
              "class",
              "e1071")

installed_packages <- packages %in% 
  rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

# Activación de paquetes
library(readxl)
library(PerformanceAnalytics)
library(tidyr)
library(dplyr)
library(ggplot2)
library(knitr)
library(tibble)
library(gt)
library(kableExtra)
library(ez)
library(GGally)
library(corrplot)
library(stats)
library(ggcorrplot)
library(tree)
library(car)
library(ISLR2)
library(class)
library(e1071)
```

# Resumen 

Las empresass editoriales están en una transición donde el papel se está viendo sobrepasado por todo lo que pueda sonar a "digital". En este sentido, en España, las empresas editoriales siempre han ido teniendo cierta importancia gracias a que son una vía de posicionamiento y puesta en valor de la creación artística y literaria de miles de autores, así como por ser canal de producción de productos relacionados con numerosos ámbitos (educativos, ocio, revistas, etc.). En este mismo sentido, es de interés, aplicar técnicas de aprendizaje estadístico para poder dar uso a diferentes métodos de predicción y clasificación, utilizando para ello R. Por tanto, en este proyecto se han aplicado dichas técnicas al caso de empresas editoriales españolas, a partir de la base de datos de Sabi, con el objetivo de realizar y aplicar técnicas predictivas y de análisis y aprendizaje estadístico.

# Importación y tratamiento de datos

Se han utilizado datos de **370 empresas editoriales españolas**, extraídas de la base de datos empresariales Sabi (licencia: [UCLM](https://www.biblioteca.uclm.es/encuentra-informacion/recursos/basesdedatos)), y obteniéndose un _dataset_ bidimensional sobre las editoriales españolas. Su dimensión es de 370 x 15, con una columna identificativa con el nombre de empresa y un conjunto de variables económicas, siendo éstas:

  + **reneco**: la rentabilidad económica de la empresa. Es el resultado de dividir el resultado del ejercicio entre los activos empresariales.
  + **renfin**: la rentabilidad financiera de la empresa. Es el resultado de dividir el resultado del ejercicio entre los fondos propios.
  + **liquidez**: la liquidez de la empresa. Es el resultado de dividir los activos líquidos de la empresa entre sus deudas.
  + **endeuda**: el nivel de endeudamiento de la empresa. Es el resultado de dividir las deudas entre el total de activos.
  + **fpios**: fondos propios. Cantidad absoluta, en miles de euros, de fondos propios de la empresa.
 + **res**: resultado del ejercicio. Resultado del ejercicio absoluto, en miles de euros. 
 + **ing**: ingresos de explotación. Ingresos del ejercicio absolutos, en miles de euros.
 + **margen**: margen financiero. Es el resultado de dividir el resultado del ejercicio entre los ingressos de explotación.
 + **solvencia**: ratio de solvencia. Es el resultado de dividir el activo a corto plazo entre el pasivo a corto plazo, indicando la capacidad de la empresa de pagar sus deudas a corto plazo. 
 + **apalanca**: apalancamiento. Es el resultado de dividir la deuda entre los fondos propios.
 + **tamaño**: Tamaño de la empresa. Para generar esta variable cualitativa, hemos clasificado las empresas según el número de trabajadores.
 + **beneficio**: beneficio de la empresa. Hemos generado esta variable binaria según si la empresa tiene beneficios o pérdidas durante el ejercicio. 1 indica la existencia de beneficios, y 0 de pérdidas.

```{r importacion, include = FALSE}
# Importando los datos de un archivo .rds
editoriales <- 
  readRDS('dataset_aprendizaje.rds')
editoriales <- 
  data.frame(editoriales,
             row.names = 1)
editoriales$tamaño <-
  factor(editoriales$tamaño,
         levels = c("microempresa", 
                    "pequeña",
                    "mediana", 
                    "grande"), 
         labels = c("microempresa",
                    "pequeña", 
                    "mediana", 
                    "grande"))
```

Cabe decir que se han dividido los datos en un conjunto de **entrenamiento** (train) y otro de **validación** (test), para lo que se ha fijado la semilla para que el resultado sea, oportunamente reproducible.

```{r division, include = FALSE}
# Partiendo la muestra en test y train
set.seed(1)
train <- 
  sample(300,
         70)
```

# Análisis exploratorio de datos

En este primer capítulo se va a proceder a realizar un análisis exploratorio de los datos con los que se va a trabajar para conocer tentativamente sus características.

## Análisis de correlaciones

Así, si recurrimos, en primer lugar, a una **visualización de las correlaciones** entre las variables, encontramos que las mayores correlaciones positivas se dan entre activo y fondos propios y activo e ingresos de explotación. También parece considerable la correlación positiva entre la variable que recoge las empresas de tamaño grande y su relación con el número de empleados y los ingresos de explotación, lo que parece algo evidente. Por su parte, las mayores correlaciones negativas se dan entre activo y fondos propios, y entre la relación de la variable ingresos de explotación con diversas variables.

```{r correlaciones, fig.width = 10, fig.height = 5}
# ANALISIS DE CORRELACIONES
model.matrix(~0+., 
             data = editoriales) %>%
  cor(use = "pairwise.complete.obs") %>%
  ggcorrplot(show.diag = F, 
             type = "lower", 
             lab = TRUE, 
             lab_size = 2)
```

## Análisis de dispersión de datos

En este apartado estamos interesados en ver cómo se distribuyen los datos de algunas de las variables del _dataset_ utilizado. Veamos algunos ejemplos.

  + Si observamos la dispersión de la **variable emplea** (número de empleados), podremos ver que hay una serie empresas, de las analizadas, que tienen un gran número de empleados. No obstante, al no ser una medida relativa, procedamos a plantear un gráfico de dispersión de una variable relativa. 

```{r dispersion1, fig.width = 10, fig.height = 7}
# DISPERSION EMPLEA
ggplot(data = editoriales,
       aes(x = row.names(editoriales), 
           y = emplea)) +
  geom_point(size = 2, 
             alpha = 0.8, 
             colour = 'red4') +
  xlab('Empresa') +
  ylab('Empleados') + 
  ggtitle('Dispersión de la variable emplea') +
  theme_light() +
  theme(axis.text.x = element_text(angle = 90, 
                                   size = 6,
                                   hjust = 1, 
                                   vjust = 1))
```

  + En cuanto a la distribución de la **variable renfin** (rentabilidad financiera), se observa que la mayor parte de las editoriales, sitúan su rentabilidad financiera en torno a 0, aunque, no obstante, se siguen observando bastantes casos que despuntan. Ya que la media es positiva, es decir, los resultados de la muestra de rentabilidad financiera está sesgada en términos positivos, es una señal de que las empresas editoriales tienen una buena capacidad de generar beneficios a través de sus fondos propios. No obstante, esto podría venir dado por la influencia de grandes empresas que empujan a la muestra a tener un sesgo positivo, pues gráficamente observamos también algunos casos atípicos o influyentes que despuntan por la parte superior e inferior de la muestra (especialmente datos relevantes en la parte superior).

```{r dispersion2, fig.width = 10, fig.height = 7}
# DISPERSION RENFIN
ggplot(data = editoriales, 
       aes(x = row.names(editoriales), 
           y = renfin)) +
  geom_point(size = 2, 
             alpha = 0.8, 
             colour = 'red4') +
  xlab('Empresa') +
  ylab('Rentabilidad financiera') + 
  ggtitle('Dispersión de la variable renfin') +
  theme_light()+
  theme(axis.text.x = element_text(angle = 90, 
                                   size = 6,
                                   hjust = 1, 
                                   vjust = 1))
```

  + Podemos plantear también los llamados **gráficos de cajas**. Si lo hacemos para la variable **renfin** observamos cómo la mayor parte de datos atípicos se sitúan en la zona positiva de valor, pues también encontramos numerosos atípicos pero se sitúan mucho más centrados en torno a la media ya que la baja varianza de la parte central de los datos hace que R entienda como atípicos valores que no están tan lejos según parámetros humanos.
  
```{r boxplot1, fig.width = 10, fig.height = 4}
# GRAFICO CAJAS RENFIN
ggplot(data = editoriales, 
       aes(y = renfin)) +
  geom_boxplot(alpha = 0.5, 
               col = "steelblue",
               fill = "orange", 
               outlier.color = "red4",
               outlier.shape = 16,
               notch = TRUE) +
  labs(title = "Rentabilidad financiera") +
  xlab("Rentabilidad financiera")+
  ylab("Empresas") +
  geom_hline(yintercept = 0)+
  theme_light()
```

 + Si observamos un gráfico de cajas, pero en este caso viendo la relación entre **tamaño** (tamaño) y **renfin** (rentabilidad financiera), observamos que las microempresas, son las que, al tener un nivel de activos inferior, presentan mayor variación en términos de rentabilidad financiera.

```{r boxplot2, fig.width = 10, fig.height = 4}
# GRAFICO CAJAS POR GRUPOS TAMAÑO Y RENFIN
ggplot(editoriales, 
       aes(tamaño,
           renfin)) +
  ggtitle('Boxplot tamaño y reneco') +
  geom_boxplot(alpha = 0.5, 
               col = "steelblue",
               fill = "orange", 
               outlier.color = "red4",
               outlier.shape = 16,
               notch = TRUE) +
  labs(title = "Boxplot tamaño y renfin") +
  xlab("Tamaño de la empresa")+
  ylab("Rentabilidad financiera") +
  theme_light()
```

## Análisis de medias por grupos

Por último, hemos planteado un **análisis de medias por grupos**. Así, si analizamos los resultados de apalancamiento teniendo en cuenta el **beneficio** y **tamaño** de la empresa, las empresas medianas y las microempresas, tal y como hemos visto en los gráficos de cajas anteriores, se ven afectadas de forma severa por los valores atípicos (outliers), a diferencia de las empresas pequeñas y grandes. Las empresas medianas, si nos fijamos, tienen outliers por abajo, y las microempresas por arriba y por abajo. Esto explica que las empresas medianas con beneficio positivo, no tengan tampoco un dato alto o como cabría esperar de renfin (rentabilidad financiera).

```{r medias}
# MEDIAS POR GRUPOS
editoriales %>%
  group_by(beneficio, 
           tamaño) %>%
  summarise_at(vars(renfin), 
               list(renfin = mean)) %>% 
  kable()
```

# Ajuste y predicción de modelos

Tras haber analizado de forma exploratoria algunas de las variables consideradas en el dataset, en este segundo capítulo, se ha escogido la variable **renfin** (rentabilidad financiera), como variable numérica de interés, con el objetivo de predecirla a partir de las demás a través de los distintos tipos de modelos y técnicas de ajuste.

Así, el modelo de partido será el que realice una predicción de **reneco** (rentabilidad financiera), en función del **solvencia** (solvencia de la empresa), **apalanca** (apalancamiento) y **endeuda** (endeudamiento).

$renfin = f(solvencia, apalanca, endeuda)$

Para desarrollar las técnicas y ajustes de modelos, se escogerán diferentes opciones (en negrita) de entre las que a continuación se detallan, ajustando dichos modelos con los datos de entrenamiento (train) y se evaluarán cada uno de ellos, sus errores, tanto en el conjunto de entrenamiento (train) como de validació (test). En algunos de ellos, es posible que se deba realizar validación cruzada.

  + KNN
  + **Regresión lineal múltiple**
  + **Regresión lineal múltiple con selección de variables**
  + Regresión de Ridge
  + Lasso
  + GAM
  + PCR
  + PLS
  + **Árbol de regresión**
  + Árboles usando bagging y boosting
  + Random Forests
  + SVMs

La realización de estas técnicas y ajustes de modelos, revela, de forma preliminar, que el mejor modelo para predecir **renfin** (rentabilidad financiera) es el ##################.

## Regresión Lineal Múltiple / Multiple Linear Regression

En primer lugar, se propone construir un **modelo de regresión múltiple**, el cual se estimará a través de mínimos cuadrados. 

  +   La **primera estimación** con todas las variables consideradas en el dataset arroja una capacidad predictiva alta (véase el coeficiente de determinación ajustado), algo que resulta evidente si se tiene en cuenta que se han considerado todas las exógenas. Veamos la alta significación de variables como apalanca, solvencia, margen, res, activo, endeuda o reneco, todas relacionadas directa, o indirectamente, en términos de contabilidad y relaciones económicas, con la rentabilidad financiera. No supondrá esta cuestión problemas de multicolinealidad si recordamos el análisis de correlaciones, pues la variable renfin no presentaba altas correlaciones positivas o negativas con ninguna variable en concreto. Por otra parte, si se observan los valores del índice de **inflación de la varianza (vif)**, se observa que únicamente dos variables podrían dar problemas de multicolinealidad (emplea y res) al ser su valor superior a 4 (aunque el análisis gráfico de correlaciones no lo mostrara).

```{r rlm1}
# Multiple Linear Regression (ALL ITEMS)
lm1.fit <- 
  lm(renfin ~ .,
     data = editoriales,
     subset = train)
summary(lm1.fit)
vif(lm1.fit)
```

  +   En la **segunda estimación** se acota la estimación considerando la ecuación inicial propuesta ($renfin = f(solvencia, apalanca, endeuda)$), donde la capacidad predictiva baja de forma notable respecto a la primera ecuación, aunque se puede considerar una buena capacidad explicativa del modelo a la hora de determinar las relaciones entre las exógenas y la variable dependiente. Se observa cómo las tres variables se relacionan positivamente con la rentabilidad financiera. Esto significa que la emprea consigue a través de determinados recursos financieros concretos mejorar sus resultados, en este caso el financiero, al relacionarse positivamente con el apalancamiento. Por otra parte, la solvencia también permite mejorar la rentabilidad financiera, es decir, el desahogo financiero (capacidad de hacer frenta a los pagos o pasivos a corto plazo) le permite mejorar su situación de renfin. Y por último, el endeudamiento, que puede venir dado por el uso de esos recursos financieros extraordinarios mencionados, hace a la empresa también tener mejor situación de renfin. En este caso el análisis de inflación de la varianza (vif) sí que muestra síntomas de que pudieran existir problemas de colinealidad por sus elevados valores superiores a 4 para el caso de solvencia y endeuda.

```{r rlm2}
# Multiple Linear Regression
lm2.fit <-
  lm(renfin ~ solvencia + apalanca + endeuda,
     data = editoriales,
     subset = train)
summary(lm2.fit)
vif(lm2.fit)
```

  +   Por último, se procede a la **validación del modelo de regresión múltiple**. En este punto, calculamos el error medio del modelo generado, utilizando información de la muestra de entrenamiento.

```{r rlm2error}
# Multiple Linear Regression ERROR
attach(editoriales)
mean((renfin - predict(lm2.fit, 
                       editoriales))[-train]^2)
```

## Árbol de regresión / Regression tree

En este segundo apartado se va a proceder a ajustar un **árbol de regresión** sobre la base de datos de editoriales que se está utilizando.

  +   En primer lugar, se creala muestra de entrenamiento y se ajusta el árbol a los datos de entrenamiento. Los resultados nos indican que tenemos que usar 4 variables para construir el árbol. En el contexto del árbol de regresión, la desviación es la suma de los cuadrados de los errores del árbol.
  
```{r tree1}
set.seed(1)
train2 <- 
  sample(1:nrow(editoriales), 
         nrow(editoriales) / 2)
tree.editoriales <- 
  tree(reneco ~ .,
       editoriales,
       subset = train2)
summary(tree.editoriales)
```

  + A continuación, se puede **visualizar gráficamente el árbol**. Vemos que la variable que nos ayuda a dividir los datos en grupos más iguales es el margen. El punto de división del margen es 6,73. Si es mayor, el rendimiento será más alto, y si es menor, viceversa. En la parte superior del margen, la siguiente variable que permite sacar conclusiones es la rentabilidad financiera, y en menor medida el endeudamiento. Las empresas con rentabilidad financiera más alta, tendrán un mayor endeudamiento. Las empresas con menor margen, se seguirán dividiendo los grupos por margen, y las que tengan un menor margen, y un número de empleados mayores, serán el subgrupo con los peores datos de rendimiento.

```{r plot_tree1, fig.width = 10, fig.height = 4}
plot(tree.editoriales)
text(tree.editoriales,
     pretty = 0)
```

  +   En este punto, cabe plantearse si reducir las divisiones permite mejorar los resultados obtenidos. Se observa que no es necesario reducir las divisiones para mejorar el árbol al observar el siguiente gráfico.
  
```{r plot_tree2, fig.width = 10, fig.height = 4}
cv.editoriales <- 
  cv.tree(tree.editoriales)
plot(cv.editoriales$size, 
     cv.editoriales$dev, 
     type = "b")
```

  + Ya se pueden realizar las **predicciones de la muestra de validación**. En primer lugar, si se observa el gráfico, el modelo captura de forma bastante aceptable los subgrupos y, si bien un árbol de regresión, al trabajar con medias de subgrupos, puede tener un mayor error, ahora se procederá a comparar con el resto. Respecto al dato del error medio obtenido, el MSE del conjunto de prueba asociado con el árbol de regresión es de 76,31, muestra que el modelo es mejor que el de regresión lineal múltiple.

```{r tree_pred, fig.width = 10, fig.height = 4}
yhat <- 
  predict(tree.editoriales,
          newdata = editoriales[-train2, ])
editoriales.test <- 
  editoriales[-train2,
              "reneco"]
plot(yhat,
     editoriales.test)
abline(0,
       1)
mean((yhat - editoriales.test)^2)
```

# Clasificación

En este tercer capítulo, se ha escogido la variable **tamaño** como una variable **categórica**, para predecir a partir del resto de las consideradas.

Para desarrollar las técnicas y ajustes de modelos, se escogerán diferentes opciones (en negrita) de entre las que a continuación se detallan, ajustando dichos modelos con los datos de entrenamiento (train) y se evaluarán cada uno de ellos, sus errores, tanto en el conjunto de entrenamiento (train) como de validació (test). En algunos de ellos, es posible que se deba realizar validación cruzada.

- **KNN**
- Regresión Logística
- Discriminante lineal y cuadrático
- GAM para respuesta categórica
- **Árbol de regresión**
- Árboles usando bagging y boosting
- Random Forests
- **SVMs**

Recordemos que el procedimiento genérico de ajuste de modelos suele seguir la siguiente estructuración:

  1. Ajustar modelo en datos _train_
  2. Predecir respuesta en datos _test_
  3. Evaluar el error en datos _test_ y _train_
  4. Repetir para distintos modelos
  5. Comparar los modelos

```{r class1, include = FALSE }
attach(editoriales)
```

## Árbol de clasificación / Classification tree

En esta sección se procederá a realizar un árbol de clasificación y una validación cruzada. 

  +   El árbol de clasificación **sobre la muestra de entrenamiento** (train), arroja una predicción cuyo acierto es del 80,50%. Por ejemplo, predice 141 microempresas de forma exacta, y por otro lado, por ejemplo, predice una microempresa como empresa grande. 

```{r treeclass1}
set.seed(1)
train3 <- 
  sample(1:nrow(editoriales),
         200)
editoriales.test2 <- 
  editoriales[-train3, ]
tamaño.test <- 
  tamaño[-train3]
tree.editoriales2 <- 
  tree(tamaño ~ . - emplea, 
       editoriales,
       subset = train3)
tree.pred <- predict(tree.editoriales2, 
                     editoriales.test2,
    type = "class")
table(tree.pred, 
      tamaño.test)
(141+14+2+4)/200
```
  
  + Respecto a la **predicción sobre el total** de los datos considerados (train y test), el acierto aumenta a un 91,62%, un dato incluso superior que sobre la muestra de entrenamiento, fruto a que la muestra de entrenamiento seleccionada sea, seguramente, más difícil de predecir que si se hace, como hemos visto, sobre la muestra total (puede ser por errores más altos).

```{r treeclass2}
tree.predtotal <- 
  predict(tree.editoriales2, 
          editoriales,
    type = "class")
table(tree.predtotal, 
      tamaño)
(308+10+7+14)/370
```

## SVM

A continuación, tras haber realizado el árbol de clasificación, y haber observado su capacidad predictiva, se opta por un **Support Vector Machine (SVM)**.

  + Dicha metodología nos muestra cómo el modelo pierde capacidad predictiva respecto al árbol de clasificación en el total del conjunto (en la muestra de test tiene un 89% de acierto frente el 91% obtenido mediante un método de árbol de clasificación en el total del conjunto). Esto supone perder, además, interpretabilidad, con lo que vamos a plantear utilizar otro modelo.
  
```{r svm}
set.seed(1)
fit.svm <- 
  svm(tamaño ~.,
      data = editoriales,
      kernel = "linear",
      cost = 0.1,
      scale = TRUE,
      subset = train3)
svm.predtotal <- 
  predict(fit.svm, 
          editoriales,
    type = "class")
table(svm.predtotal, 
      tamaño)
(311+3+3+15)/370
```

## KNN

En este tercer, y último intento, se ha realizado una predicción utilizando el método de *k-vecinos*, obteniendo resultados para ambas muestras (entrenamiento y validación), escogiéndose 4 grupos de k-vecinos al tener 4 tipos de empresas **tamaño** (tamaños de empresas).

  +   Los resultados arrojan, para ambas muestras, un acierto en la predicción de entorno al 90%, algo ligeramente superior en la muestra de entrenamiento. 
  + Si se compara con la predicción del árbol de clasificación (91,6% en muestra de validación), se observa que el método de k-vecinos es mínimamente peor que el árbol de clasificación. Por otro lado, de forma complementaria, cabe decir que el árbol de clasificación acertaba en la predicción un 80,5%, mientras que el método de k-vecinos es prácticamente un 10% superior (91,40%). 
  + En este punto cabe decir que **el método de k-vecinos sería mejor a la hora de predecir**, aunque el árbol de clasificación es más intepretable al no caer en lo automático del otro método (calcula distancias y predice de forma directa).

```{r knn1, include = FALSE}
train3 <-
  c(rep(TRUE,
        280),
    rep(FALSE,
        90))
set.seed(1)
attach(editoriales)
train.X <-   
  cbind(reneco,
        renfin,
        liquidez,
        solvencia,
        ing,
        endeuda,
        emplea,
        activo,
        fpios,
        res,
        ing,
        margen,
        apalanca,
        beneficio)[train3, ]
test.X <- 
  cbind(reneco,
        renfin,
        liquidez,
        solvencia,
        ing,
        endeuda,
        emplea,
        activo,
        fpios,
        res,
        ing,
        margen,
        apalanca,
        beneficio)[!train3, ]
train.tamaño <- 
  tamaño[train3]
```

```{r knn2}
tamaño5 <- 
  tamaño[!train3]
tamaño6 <- 
  tamaño[train3]
set.seed(1)
knn.predtrain <- 
  knn(train.X,
      train.X,
      train.tamaño,
      k = 4)
table(knn.predtrain, 
      tamaño6)
(227+10+9+10)/280
```

```{r knn3}
knn.predtest <- 
  knn(train.X,
      test.X,
      train.tamaño,
      k = 4)
table(knn.predtest, 
      tamaño5)
(75+2+5)/90
```

# Conclusiones

Hemos analizado dos variables distintas sobre las empresas editoriales en España, su rentabilidad financiera por un lado y su tamaño, por otro. 

Respecto a la primera, hemos usado métodos que nos dan una explicación detallada del modelo generado como son la regresión lineal múltiple y un árbol de regresión. Gracias a ellos, hemos visto que la rentabilidad depende en mayor parte de su margen financiero, y en segundo lugar del endeudamiento y el número de empleados. El modelo que nos ha dado mejores predicciones, comprobado usando validación cruzada, ha sido el árbol de regresión. Ya que nuestra muestra no es tan grande, no hemos llevado a cabo k-folding para la validación. 

Respecto a la clasificación, hemos usado primero un árbol de clasificación, que si bien es  muy interpretable, al compararlo con otros métodos vimos que tenía un sesgo mayor, usando la matriz de confusión del conjunto de entrenamiento como métrica. Al usar una máquina de vectores de soporte, aunque no podamos interpretar cómo se había llegado a las predicciones del modelo, nos da una mayor tasa de acierto. Decidimos tomar una solución intermedia usando el modelo de k-vecinos, que sabemos que toma una distancia entre los  puntos para formar grupos pero para recarlcularla manualmente no es tan sencillo como un modelo logit, mucho menos un árbol de clasificación. Sin embargo, al ser el modelo que menor error nos da, es el que usaríamos para predecir si una empresa es grande, mediana, pequeña o microempresa.

# Referencias

En esta sección se incluyen las referencias bibliográficas utilizadas para el desarrollo del proyecto.

[Cano, E. (2022). Introducción al software estadístico R. https://www.lcano.com/b/iser/_book/index.html](https://www.lcano.com/b/iser/_book/index.html)

[James, G. et al. (2021). An introduction to Statistical Learning with Applications in R. Second Edition. Springer](https://www.statlearning.com/)


# Anexos

## Anexo 1. Datos de la sesión

En esta sección se recogen los datos de la sesión utilizada para elaborar este informe. Es fundamental observar la **versión de R**, así como las versiones de los paquetes bajo los cuales se ha ejecutado el código o *script*.

```{r}
sessionInfo()
```

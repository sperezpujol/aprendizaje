---
title: "Técnicas de Aprendizaje Estadístico aplicadas a empresas editoriales españolas"
subtitle: "Máster Universitario en Modelización y Análisis de Datos Económicos <p> (MUMADE)"
author: 'Autores: Bermann, M.A. & Pérez, R.S.'
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
    prettydoc::html_pretty:
    theme: cayman
    highlight: vignette
lang: es
---

```{r setup, include = FALSE}
# Ajustes de los chunk
knitr::opts_chunk$set(echo = FALSE, 
                      eval = TRUE, 
                      message = FALSE,
                      warning = FALSE,
                      comment = '')
```

```{r}
# Limpieza inicial del entorno
rm(list = ls())

# Instalación de paquetes que no estén instalados
packages <- c("tidyr", "dplyr", "ggplot2", "knitr", 
              "readxl", "tibble", "kableExtra", "gt",
              "PerformanceAnalytics")
installed_packages <- packages %in% 
  rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

# Activación de paquetes
library(readxl)
library(PerformanceAnalytics)
library(tidyr)
library(dplyr)
library(ggplot2)
library(knitr)
library(tibble)
library(gt)
library(kableExtra)
library(ez)
library(GGally)
library(corrplot)
library(stats)
library(ggcorrplot)
```

# Resumen 

Las empresass editoriales están en una transición donde el papel se está viendo sobrepasado por todo lo que pueda sonar a "digital". En este sentido, en España, las empresas editoriales siempre han ido teniendo cierta importancia gracias a que son una vía de posicionamiento y puesta en valor de la creación artística y literaria de miles de autores, así como por ser canal de producción de productos relacionados con numerosos ámbitos (educativos, revistas, etc.). En este sentido, es de interés, aplicar técnicas de aprendizaje estadístico para poder dar uso a diferentes métodos de predicción y clasificación, utilizando para ello R.

# Importación de datos

Se han utilizado datos de 370 empresas editoriales españolas, extraídas de la base de datos empresariales Sabi (licencia: UCLM), y obteniéndose un _dataset_ bidimensional sobre las editoriales españolas. Su dimensión es de 370 x 15, con una columna identificativa con el nombre de empresa y un conjunto de variables económicas, siendo éstas:

  + reneco: la rentabilidad económica de la empresa. Es el resultado de dividir el resultado del ejercicio entre los activos empresariales.
  + renfin: la rentabilidad financiera de la empresa. Es el resultado de dividir el resultado del ejercicio entre los fondos propios.
  + liquidez: la liquidez de la empresa. Es el resultado de dividir los activos líquidos de la empresa entre sus deudas.
  + endeuda: el nivel de endeudamiento de la empresa. Es el resultado de dividir las deudas entre el total de activos.
  + fpios: fondos propios. Cantidad absoluta, en miles de euros, de fondos propios de la empresa.
 + res: resultado del ejercicio. Resultado del ejercicio absoluto, en miles de euros. 
 + ing: ingresos de explotación. Ingresos del ejercicio absolutos, en miles de euros.
 + margen: margen financiero. Es el resultado de dividir el resultado del ejercicio entre los ingressos de explotación.
 + solvencia: ratio de solvencia. Es el resultado de dividir el activo a corto plazo entre el pasivo a corto plazo, indicando la capacidad de la empresa de pagar sus deudas a corto plazo. 
 + apalanca: apalancamiento. Es el resultado de dividir la deuda entre los fondos propios.
 + tamaño: Tamaño de la empresa. Para generar esta variable cualitativa, hemos clasificado las empresas según el número de trabajadores.
 +beneficio: beneficio de la empresa. Hemos generado esta variable binaria según si la empresa tiene beneficios o pérdidas durante el ejercicio. 1 indica la existencia de beneficios, y 0 de pérdidas.

```{r}
# Importando los datos de un archivo .rds
editoriales <- 
  readRDS('dataset_aprendizaje.rds')
editoriales <- 
  data.frame(editoriales, row.names = 1)
editoriales$tamaño <-
  factor(editoriales$tamaño,
         levels = c("microempresa", 
                    "pequeña",
                    "mediana", 
                    "grande"), 
         labels = c("microempresa",
                    "pequeña", 
                    "mediana", 
                    "grande"))
```

En este apartado podéis hacer la división en conjuntos de entrenamiento y test. Podéis usar el método de los índices como en los _labs_ del libro, para poder reutilizar al máximo el código. Fijad la semilla para que el resultado sea reproducible al corregir.

```{r}
# Partiendo la muestra en test y train
library(ISLR2)
set.seed(1)
train <- slice_sample(editoriales, 
                      n = 300)
```

# Regresión

Elige una variable **numérica** de interés del conjunto de datos, que tenga sentido predecir a partir de las demás. Si estás usando los datos de RRHH, la empresa podría estar interesada en predecir el nivel de satisfacción en función de las demás. Haz algunos gráficos y resúmenes numéricos para explorar las relaciones (correlaciones de variables numéricas, gráficos de cajas por grupos, medias por grupos, ...)

renfin ~ tamaño ing emplea activo

```{r, fig.width = 5, fig.height = 7}
# ANÁLISIS DE CORRELACIONES
model.matrix(~0+., data = editoriales) %>%
  cor(use = "pairwise.complete.obs") %>%
  ggcorrplot(show.diag = F, type = "lower", lab=TRUE, lab_size=2)

#DISPERSION
ggplot(data = editoriales, aes(x = row.names(editoriales), y = emplea)) +
  geom_point(size = 2, alpha = 0.8, colour = 'orange') +
  xlab('Empresa') +
  ylab('Empleados') + ggtitle('') +
  theme_light()+
  theme(axis.text.x = element_text(angle = 90, size = 6,hjust = 1, vjust = 1))

ggplot(data = editoriales, aes(y = reneco)) +
  geom_boxplot(alpha = 0.5, 
               col = "steelblue",
               fill = "orange", 
               outlier.color = "blue",
               outlier.shape = 16,
               notch = TRUE) +
  labs(title ="Rentabilidad económica") +
  xlab("Rentabilidad económica")+
  ylab("Empresas") +
  geom_hline(yintercept = 0)+
  theme_light()

ggplot(editoriales, aes(tamaño, activo)) +
  geom_boxplot()
# GRÁFICAS DE CAJAS POR GRUPOS
library(plotly)
fig <- plot_ly(y = ~rnorm(50), type = "box")
fig <- fig %>% add_trace(y = ~rnorm(50, 1))
fig
# MEDIAS POR GRUPOS
editoriales %>%
  group_by(beneficio) %>%
  summarise_at(vars(apalanca), list(name = mean))
# EXPLORATORIO
```

Ajusta **algunos** de los siguientes modelos que hemos aprendido en la asignatura con los datos de entrenamiento, y evalúa los errores en los dos conjuntos. Usa validación cruzada en aquellos en los que se haya usado en los _labs_:

- KNN
- Regresión lineal múltiple
- Regresión lineal múltiple con selección de variables
- Regresión de Ridge
- Lasso
- GAM
- PCR
- PLS
- Árbol de regresión
- Árboles usando bagging y boosting
- Random Forests
- SVMs

No es obligatorio que los hagáis todos. El mínimo es dos, para poder comparar. El código de los _labs_ os debe servir modificándolo para vuestros datos.

Aunque luego lo pongas en las conclusiones, explica aquí cuál es el mejor modelo para predecir la variable que has elegido.

# Clasificación

Elige una variable **categórica** de interés del conjunto de datos, que tenga sentido predecir a partir de las demás. Si estás usando los datos de RRHH, la empresa podría estar interesada en predecir el abandono en función de las demás. Haz algunos gráficos y resúmenes numéricos para explorar las relaciones (algunos del apartado de regresión servirán para este.

Ajusta **algunos** de los siguientes modelos que hemos aprendido en la asignatura con los datos de entrenamiento, y evalúa los errores en los dos conjuntos. Usa validación cruzada en aquellos en los que se haya usado en los _labs_:

- KNN
- Regresión Logística
- Discriminante lineal y cuadrático
- GAM para respuesta categórica
- Árbol de regresión
- Árboles usando bagging y boosting
- Random Forests
- SVMs

Recuerda que aunque hay muchos modelos, el procedimiento es similar en todos:

1. Ajustar modelo en datos _train_
2. Predecir respuesta en datos _test_
3. Evaluar el error en datos _test_ y _train_
4. Repetir para distintos modelos
5. Comparar los modelos

Empieza por dos modelos que te resultan más fáciles, y después ve probando más. No es obligatorio ajustarlos todos.


# Conclusiones

Incluid unas breves conclusiones, uno o dos párrafos comentando los resultados.


# Referencias

Podéis incluir anexos y referencias si queréis, aunque no es necesario para el objetivo de este trabajo

# Anexos

## Anexo 1. Datos de la sesión

En esta sección se recogen los datos de la sesión utilizada para elaborar este informe. Es fundamental observar la versión de R, así como las versiones de los paquetes bajo los cuales se ha ejecutado el código o *script*.

```{r}
sessionInfo()
```
